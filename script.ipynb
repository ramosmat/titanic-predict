{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding a Predict model to predict whether the passanger of the titanic will survive or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary libraries\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reading train dataset and taking a first look at it\n",
    "dataset = pd.read_csv(r'train.csv')\n",
    "\n",
    "dataset.info() #Columns with null values: age, cabin, embarked\n",
    "# dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at the first lines of the dataset\n",
    "# According to Kaggle, the column Survived is the one that we gonna use to train our predict model\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the NaN values with median of the own column\n",
    "# Filling Cabin and Embarked NaN values with a new category: Unknown\n",
    "dataset['Age'] = dataset['Age'].fillna(dataset['Age'].median())\n",
    "dataset['Cabin'] = dataset['Cabin'].fillna('Unknown')\n",
    "dataset['Embarked'] = dataset['Embarked'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since modeling works only with numbers, we will transform non numeric columns into numeric ones, using LabelEncoder.\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "dataset['Name'] = encoder.fit_transform(dataset['Name'])\n",
    "dataset['Sex'] = encoder.fit_transform(dataset['Sex'])\n",
    "dataset['Ticket'] = encoder.fit_transform(dataset['Ticket'])\n",
    "dataset['Cabin'] = encoder.fit_transform(dataset['Cabin'])\n",
    "dataset['Embarked'] = encoder.fit_transform(dataset['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns that will not be used for model training, those will be stored as X and y, y beeing the target values\n",
    "X = dataset.drop(['Survived', 'PassengerId'], axis = 1).values #Colum ID will be removed as well, because ir can interfere with model training\n",
    "y = dataset['Survived'].values\n",
    "\n",
    "# Separating dataset into train and test variables. Since it is a small amount of data, we will consider 30% as test size.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an instance of the predicting model. We will do a comparission of three models: LogisticRegression, RandomForest and KNeighborsClassifier. It will be compared using the Accuracy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of LogisticRegression\n",
    "logr = LogisticRegression()\n",
    "\n",
    "# Fitting our model using the train variables\n",
    "logr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting our data from the test variables\n",
    "logr_prediction = logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Fitting our model using the train variables\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Predicting our data from the test variables\n",
    "forest_prediction = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for n_neighbors: 6\n"
     ]
    }
   ],
   "source": [
    "# Getting the best number of neighbors:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_values = range(1, 21)  # Testar n_neighbors de 1 a 20\n",
    "\n",
    "# List to store results\n",
    "scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Cross validation with 5 divisions\n",
    "    score = cross_val_score(knn, X, y, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "# Find the k value with best performance\n",
    "best_k = k_values[np.argmax(scores)]\n",
    "print(f\"Best value for n_neighbors: {best_k}\") # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fitting our model using the train variables\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predicting our data from the test variables\n",
    "knn_prediction = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for LogisticRegression: 81.34%\n",
      "Accuracy for RandomForest: 85.07%\n",
      "Accuracy for KNeighbors: 63.06%\n"
     ]
    }
   ],
   "source": [
    "# Printing the Accuracy of each model.\n",
    "logr_accuracy = accuracy_score(y_test, logr_prediction)\n",
    "forest_accuracy = accuracy_score(y_test, forest_prediction)\n",
    "knn_accuracy = accuracy_score(y_test, knn_prediction)\n",
    "\n",
    "print(f'Accuracy for LogisticRegression: {format(np.round(logr_accuracy * 100, 2))}%')\n",
    "print(f'Accuracy for RandomForest: {format(np.round(forest_accuracy * 100, 2))}%')\n",
    "print(f'Accuracy for KNeighbors: {format(np.round(knn_accuracy * 100, 2))}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that RandomForest was the best Supervised Model for this dataset.\n",
    "Now lets use the trained model in the test dataset to see whether each passanger will survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Importing test dataset\n",
    "testdf = pd.read_csv(r'test.csv')\n",
    "\n",
    "testdf.info() #Columns with null values: age, fare, cabin, embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the ID Column\n",
    "testdf.drop(columns=['PassengerId'], inplace=True)\n",
    "\n",
    "# Filling the NaN values with median of the own column\n",
    "# Filling Cabin and Embarked NaN values with a new category: Unknown\n",
    "testdf['Age'] = testdf['Age'].fillna(testdf['Age'].median())\n",
    "testdf['Fare'] = testdf['Fare'].fillna(testdf['Fare'].median())\n",
    "testdf['Cabin'] = testdf['Cabin'].fillna('Unknown')\n",
    "testdf['Embarked'] = testdf['Age'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "testdf['Name'] = encoder.fit_transform(testdf['Name'])\n",
    "testdf['Sex'] = encoder.fit_transform(testdf['Sex'])\n",
    "testdf['Ticket'] = encoder.fit_transform(testdf['Ticket'])\n",
    "testdf['Cabin'] = encoder.fit_transform(testdf['Cabin'])\n",
    "testdf['Embarked'] = encoder.fit_transform(testdf['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting with RandomForest previously trained\n",
    "predict = forest.predict(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>76</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>76</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>76</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>353</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>22</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>332</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Name  Sex   Age  SibSp  Parch  Ticket      Fare  Cabin  Embarked  \\\n",
       "0         3   206    1  34.5      0      0     152    7.8292     76        44   \n",
       "1         3   403    0  47.0      1      0     221    7.0000     76        60   \n",
       "2         2   269    1  62.0      0      0      73    9.6875     76        74   \n",
       "3         3   408    1  27.0      0      0     147    8.6625     76        34   \n",
       "4         3   178    0  22.0      1      1     138   12.2875     76        27   \n",
       "..      ...   ...  ...   ...    ...    ...     ...       ...    ...       ...   \n",
       "413       3   353    1  27.0      0      0     267    8.0500     76        34   \n",
       "414       1   283    0  39.0      0      0     324  108.9000     22        51   \n",
       "415       3   332    1  38.5      0      0     346    7.2500     76        50   \n",
       "416       3   384    1  27.0      0      0     220    8.0500     76        34   \n",
       "417       3   302    1  27.0      1      1     105   22.3583     76        34   \n",
       "\n",
       "     Prediction  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  \n",
       "..          ...  \n",
       "413           0  \n",
       "414           1  \n",
       "415           0  \n",
       "416           0  \n",
       "417           1  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the prediction column into the test dataset\n",
    "testdf['Prediction'] = predict\n",
    "testdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
